{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model-cnn.ipynb","provenance":[],"collapsed_sections":["TmjrsRGd4soU","fp_v3dDTX9fM","Z0xEXMTa0bpn","8FWj6aZZirUD","E1-hVE75P-Xn"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yTd_i9v56NAB"},"source":["##### Load imports and modules"]},{"cell_type":"code","metadata":{"id":"Hper9R0A5jlG","executionInfo":{"status":"ok","timestamp":1605061524995,"user_tz":-60,"elapsed":840,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"10134628738205138361"}}},"source":["params = {\n","    # Dataset parameters\n","    \"dataset\": \"dataset_half_notrim_tensors\",\n","    \"train_split\": 0.6,\n","    \"val_split\": 0.2,\n","    \"test_split\": 0.2,\n","    \n","    # Preprocessing parameters\n","    'sample_rate': 16_000, \n","    'min_freq': 0, \n","    'max_freq': 8_000\n","}\n","\n","MODEL_TYPE = \"cnn_fft\"\n","LOG_DIR = f\"/content/marvin-models/logs/{MODEL_TYPE}\"\n","LOG_LEVEL = \"ERROR\"\n","GH_TOKEN = \"73a1d93fa1e7fe7696321a86ff037a0ecc58346c\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQtIbvWVxkM0","cellView":"form","executionInfo":{"status":"ok","timestamp":1605061534303,"user_tz":-60,"elapsed":10139,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"10134628738205138361"}},"outputId":"6baf6a91-d50a-4c2d-e05b-2ef2282e4315","colab":{"base_uri":"https://localhost:8080/"}},"source":["#@markdown <b>Run me to import underscore module</b><br/>   {display-mode: \"form\"}\n","#@markdown <small>Method signatures:</small><br/> \n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _under(source_path, target_path, copy=True, auth_on_upload=True)</small></small><br/>\n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _set_gh_token(token)</small></small><br/>\n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _from_gh(user_name, repo_name, release_name) &nbsp; &nbsp; &nbsp; <b>Returns:</B> dictionary of arrays { 'array_name' : np.ndarray }</small></small><br/>\n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _to_gh(user_name, repo_name, release_name, split_size=600, **arr_kwargs)</small></small><br/>\n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _export_model(model, model_name, model_type, val_dataset, test_dataset, params, hparams, history, log_dir, n_prep_layers=None)</small></small><br/>\n","!pip install -q tensorflowjs\n","!pip install -q githubrelease\n","import numpy as np\n","import os, glob, re, time, json\n","import github_release\n","import tensorflow.keras.backend as K\n","from contextlib import redirect_stdout\n","\n","compressed_dirs = set()\n","\n","\n","def _compress(source_path, target_path, target_dir=None):\n","    if target_dir:\n","        !mkdir -p {target_dir}\n","    if target_path.endswith('.tar.gz'):\n","        !tar -czf {target_path} -C {source_path} .\n","    elif target_path.endswith('.tar'):\n","        !tar -cf {target_path} -C {source_path} .\n","    elif target_path.endswith('.zip'):\n","        !(cd {source_path} && zip -q -r {target_path} .)\n","\n","\n","def _extract(source_path, target_path):\n","    !mkdir -p {target_path}\n","    if source_path.endswith('.tar.gz'):\n","        !tar -xzf {source_path} -C {target_path}\n","    elif source_path.endswith('.tar'):\n","        !tar -xf {source_path} -C {target_path}\n","    elif source_path.endswith('.zip'):\n","        !unzip -qq {source_path} -d {target_path}\n","\n","\n","def _under(source_path, target_path, copy=True, auth_on_upload=True):\n","    \"\"\"\n","    Use cases:\n","        Movement:\n","            - GCS -> GCS\n","            - GCS -> LOCAL\n","            - LOCAL -> GCS\n","            - LOCAL -> LOCAL\n","            \n","        Compression (e.g. from dir to .tar.gz):\n","            - GCS -> GCS\n","            - GCS -> LOCAL\n","            - LOCAL -> GCS\n","            - LOCAL -> LOCAL\n","            \n","        Extraction (e.g. from .zip to dir):\n","            - GCS -> GCS\n","            - GCS -> LOCAL\n","            - LOCAL -> GCS\n","            - LOCAL -> LOCAL\n","            \n","        Extraction & compression (e.g. from .zip to .tar.gz):\n","            - GCS -> GCS\n","            - GCS -> LOCAL\n","            - LOCAL -> GCS\n","            - LOCAL -> LOCAL\n","    \"\"\"\n","    COMPRESSION_FORMATS = ('zip', 'tar', 'tar.gz')\n","    TEMP_DIR = \"/tmp_\"\n","    LOG_TEMPLATE = \"{}    from    {}    to    {}\"\n","\n","    # Source\n","    if source_path.endswith(\"/\"):\n","        source_path = source_path[:-1]\n","    source_dir, _, source_name = source_path.rpartition('/')\n","    source_isgcs = source_path.startswith(\"gs://\")\n","    source_islocal = not source_isgcs\n","    if source_islocal:\n","        source_path = os.path.abspath(source_path)\n","    source_isprefix, source_isfile, source_ext = source_name.partition('.')\n","    source_isdir = not source_isfile\n","    source_iscompression = source_ext in COMPRESSION_FORMATS\n","\n","    # Target\n","    target_dir, _, target_name = target_path.rpartition('/')\n","    target_isgcs = target_path.startswith(\"gs://\")\n","    target_islocal = not target_isgcs\n","    target_prefix, target_isfile, target_ext = target_name.partition('.')\n","    target_isdir = not target_isfile\n","    target_iscompression = target_ext in COMPRESSION_FORMATS\n","\n","    # Flags\n","    MOVE_ONLY = source_ext == target_ext\n","    GCS_ONLY = source_isgcs and target_isgcs\n","    RENAME = source_isprefix != target_prefix\n","    COMPRESSION = source_isdir and target_iscompression\n","    EXTRACTION = source_iscompression and target_isdir\n","    EXTRACTION_COMPRESSION = source_iscompression and target_iscompression and source_ext != target_ext\n","\n","    # Add forward slash if file is at root level\n","    source_dir = \"/\" if not source_dir else source_dir\n","    target_dir = \"/\" if not target_dir else target_dir\n","\n","    # Authenticate if writing to GCS\n","    if target_isgcs and auth_on_upload:\n","        from google.colab import auth\n","        auth.authenticate_user()\n","\n","    # Assert that subdirectories exist if target is local\n","    if target_islocal:\n","        !mkdir -p {target_dir}\n","\n","    # Movement commands\n","    if MOVE_ONLY:\n","        # GCS -> GCS\n","        if source_isgcs and target_isgcs:\n","            action = \"COPYING\" if copy else \"MOVING\"\n","            print(LOG_TEMPLATE.format(f\"{action} (1/1)\", source_path, target_path))\n","            if copy:\n","                !gsutil -m -q cp -r {source_path} {target_path}\n","            else:\n","                !gsutil -m -q mv {source_path} {target_path}\n","        \n","        # LOCAL -> LOCAL\n","        elif source_islocal and target_islocal:\n","            action = \"COPYING\" if copy else \"MOVING\"\n","            print(LOG_TEMPLATE.format(f\"{action} (1/1)\", source_path, target_path))\n","            if copy:\n","                !cp -r {source_path} {target_path}\n","            else:\n","                !mv {source_path} {target_path}\n","        \n","        # GCS -> LOCAL\n","        elif source_isgcs and target_islocal:\n","            if source_isdir:\n","                print(LOG_TEMPLATE.format(\"DOWNLOADING DIR (1/1)\", source_path, target_dir))\n","                !gsutil -m -q cp -r {source_path} {target_dir}\n","                if RENAME:\n","                    print(LOG_TEMPLATE.format(\"\\tRENAMING DIR\", source_isprefix, target_prefix))\n","                    !mv {target_dir}/{source_isprefix} {target_dir}/{target_prefix}\n","            else:\n","                print(LOG_TEMPLATE.format(\"DOWNLOADING FILE (1/1)\", source_path, target_path))\n","                !gsutil -m -q cp {source_path} {target_path}\n","        \n","        # LOCAL -> GCS\n","        if source_islocal and target_isgcs:\n","            if source_isdir:\n","                print(LOG_TEMPLATE.format(\"UPLOADING DIR (1/1)\", source_path, target_path))\n","                !gsutil -m -q cp -r {source_path} {target_path}\n","            else:\n","                print(LOG_TEMPLATE.format(\"UPLOADING FILE (1/1)\", source_path, target_path))\n","                !gsutil -m -q cp {source_path} {target_path}\n","        return\n","\n","\n","    # Create directory for intermediate storage if required\n","    if source_isgcs or target_isgcs or EXTRACTION_COMPRESSION:\n","        !mkdir -p {TEMP_DIR}\n","    \n","\n","    # For remaining operations, download GCS source to temp and treat as local\n","    if source_isgcs:\n","        if source_isdir:\n","            print(LOG_TEMPLATE.format(\"\\tDOWNLOADING DIR\", source_path, TEMP_DIR))\n","            !gsutil -m -q cp -r {source_path} {TEMP_DIR}\n","        else:\n","            print(LOG_TEMPLATE.format(\"\\tDOWNLOADING FILE\", source_path, f\"{TEMP_DIR}/{source_name}\"))\n","            !gsutil -m -q cp {source_path} {TEMP_DIR}/{source_name}\n","        source_path = f\"{TEMP_DIR}/{source_name}\"\n","        source_dir = TEMP_DIR\n","\n","    # Compression\n","    if COMPRESSION:\n","        if target_islocal:\n","            print(LOG_TEMPLATE.format(\"COMPRESSING (1/1)\", source_path, target_path))\n","            _compress(source_path, target_path, target_dir=target_dir)\n","        else:\n","            print(LOG_TEMPLATE.format(\"COMPRESSING (1/2)\", source_path, f\"{TEMP_DIR}/{target_name}\"))\n","            _compress(source_path, f\"{TEMP_DIR}/{target_name}\")\n","            print(LOG_TEMPLATE.format(\"UPLOADING FILE (2/2)\", f\"{TEMP_DIR}/{target_name}\", target_path))\n","            !gsutil -m -q cp {TEMP_DIR}/{target_name} {target_path}\n","\n","    # Extraction\n","    elif EXTRACTION:\n","        if target_islocal:\n","            print(LOG_TEMPLATE.format(\"EXTRACTING (1/1)\", source_path, target_path))\n","            _extract(source_path, target_path)\n","        else:\n","            print(LOG_TEMPLATE.format(\"EXTRACTING (1/2)\", source_path, f\"{TEMP_DIR}/{target_name}\"))\n","            _extract(source_path, f\"{TEMP_DIR}/{target_name}\")\n","            print(LOG_TEMPLATE.format(\"UPLOADING DIR (2/2)\", f\"{TEMP_DIR}/{target_name}\", target_path))\n","            !gsutil -m -q cp -r {TEMP_DIR}/{target_name} {target_path}\n","\n","    # Extraction & compression\n","    elif EXTRACTION_COMPRESSION:\n","        if target_islocal:\n","            print(LOG_TEMPLATE.format(\"EXTRACTING (1/2)\", source_path, f\"{TEMP_DIR}/{target_prefix}\"))\n","            _extract(source_path, f\"{TEMP_DIR}/{target_prefix}\")\n","            print(LOG_TEMPLATE.format(\"COMPRESSING (2/2)\", f\"{TEMP_DIR}/{target_prefix}\", target_path))\n","            _compress(f\"{TEMP_DIR}/{target_prefix}\", target_path, target_dir=target_dir)\n","        else:\n","            print(LOG_TEMPLATE.format(\"EXTRACTING (1/3)\", source_path, f\"{TEMP_DIR}/{target_prefix}\"))\n","            _extract(source_path, f\"{TEMP_DIR}/{target_prefix}\")\n","            print(LOG_TEMPLATE.format(\"COMPRESSING (2/3)\", f\"{TEMP_DIR}/{target_prefix}\", f\"{TEMP_DIR}/{target_name}\"))\n","            _compress(f\"{TEMP_DIR}/{target_prefix}\", f\"{TEMP_DIR}/{target_name}\")\n","            print(LOG_TEMPLATE.format(\"UPLOADING FILE (3/3)\", f\"{TEMP_DIR}/{target_name}\", target_path))\n","            !gsutil -m -q cp {TEMP_DIR}/{target_name} {target_path}\n","    \n","    # Cleanup intermediate storage\n","    !rm -rf {TEMP_DIR}\n","\n","def _set_gh_token(token):\n","    os.environ[\"GITHUB_TOKEN\"] = token\n","\n","\n","def _export_array(array, release_name, prefix=\"\", splits=3):\n","    dir_path = f\"/tmp_/{release_name}\"\n","    !mkdir -p {dir_path}\n","    n_digits = len(str(splits - 1))\n","    subarrays = np.array_split(array, splits)\n","    for i, subarray in enumerate(subarrays):\n","        filename = f\"{prefix}__{str(i).zfill(n_digits)}.npy\"\n","        np.save(f\"{dir_path}/{filename}\", subarray)\n","\n","\n","def _concat_arrays(paths):\n","    return np.concatenate([np.load(path, allow_pickle=True) for path in sorted(paths)])\n","\n","\n","def _to_gh(user_name, repo_name, release_name, split_size=600, **arr_kwargs):\n","    # Assert that GitHub Auth token is set\n","    if \"GITHUB_TOKEN\" not in os.environ:\n","        print(\"GitHub authentication token is not set.\")\n","        print(\"Set token using the '_set_gh_token(token_string)' method.\")\n","        print(\"Minimal required auth scope is 'repo/public_repo' for public repositories.\")\n","        print(\"URL: https://github.com/settings/tokens/new\")\n","        return\n","\n","    # Split arrays\n","    for prefix, array in arr_kwargs.items():\n","        splits = int((array.nbytes/1_000_000) // split_size) + 1\n","        _export_array(array, release_name, prefix=prefix, splits=splits)\n","\n","    # Upload arrays\n","    github_release.gh_release_create(\n","        f\"{user_name}/{repo_name}\", \n","        release_name, \n","        publish=True, \n","        name=release_name, \n","        asset_pattern=f\"/tmp_/{release_name}/*\"\n","    )\n","    !rm -rf /tmp_/*\n","\n","\n","def _from_gh(user_name, repo_name, release_name):\n","    # Download release to temporary directory\n","    print(\"Downloading dataset in parallell ... \", end='\\t')\n","    t0 = time.perf_counter()\n","    assets = github_release.get_assets(f\"{user_name}/{repo_name}\", tag_name=release_name)\n","    download_urls = [asset['browser_download_url'] for asset in assets]\n","    urls_str = \" \".join(download_urls)\n","    !echo {urls_str} | xargs -n 1 -P 8 wget -q -P /tmp_/{release_name}_dl/\n","    t1 = time.perf_counter()\n","    print(f\"done! ({t1 - t0:.3f} seconds)\")\n","\n","    # Load data into numpy arrays\n","    paths = glob.glob(f\"/tmp_/{release_name}_dl/*.npy\")\n","    groups = {}\n","    for path in paths:\n","        match = re.match(r\".*/(.*)__[0-9]*\\.npy\", path)\n","        if match:\n","            prefix = match.group(1)\n","            groups[prefix] = groups.get(prefix, []) + [path]\n","    arrays_dict = {name: _concat_arrays(paths) for name, paths in groups.items()}\n","    !rm -rf /tmp_/*\n","    return arrays_dict\n","    \n","\n","def _log_to_gh(user, repo, tag, log_dir=\"/tmp/logs\"):\n","    # Create temporary directory for compressed logs\n","    !mkdir -p /tmp/compressed_logs\n","    \n","    # Compress all directories in log dir\n","    for dirname in os.listdir(log_dir):\n","        # Skip files\n","        if \".\" in dirname or dirname in compressed_dirs:\n","            continue\n","\n","        # Compress\n","        _under(f\"{log_dir}/{dirname}\", f\"/tmp/compressed_logs/{dirname}.tar.gz\")\n","        compressed_dirs.add(dirname)\n","\n","    # Upload compressed logs to GitHub\n","    github_release.gh_asset_upload(f\"{user}/{repo}\", tag, f\"/tmp/compressed_logs/*.tar.gz\")\n","\n","    # Cleanup compressed logs\n","    !rm -rf /tmp/compressed_logs/*\n","\n","def timeit(method):\n","    def timed(*args, **kw):\n","        ts = time.perf_counter()\n","        result = method(*args, **kw)\n","        te = time.perf_counter()\n","        diff = te - ts\n","        print(f\"{method.__name__}: {diff:.8f} s\")\n","        return result\n","    return timed\n","\n","class NpEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, np.integer):\n","            return int(obj)\n","        elif isinstance(obj, np.floating):\n","            return float(obj)\n","        elif isinstance(obj, np.ndarray):\n","            return obj.tolist()\n","        else:\n","            return super(NpEncoder, self).default(obj)\n","\n","@timeit\n","def _export_model(model, model_name, model_type, val_dataset, test_dataset, params, hparams, history, log_dir, n_prep_layers=None):\n","    # Create temporary directory\n","    target_dir = f\"/tmp/models/{model_type}/{model_name}\"\n","    !mkdir -p {target_dir}     #/tmp_/models/rnn_naive/rnn_naive_20201108_130308\n","\n","    # Write export logs to file\n","    export_logs_path = os.path.join(target_dir, \"export_logs.txt\")\n","    with open(export_logs_path, 'w') as export_logs:\n","        with redirect_stdout(export_logs):\n","            # Profile model on inputs (average of n_runs cycles)\n","            n_runs = 5\n","            input_shape = val_dataset.element_spec[0].shape\n","\n","            def time_examples(model, n):\n","                dummy = np.random.rand(n, *input_shape[1:])\n","                t0 = time.perf_counter()\n","                model.predict(dummy)\n","                return time.perf_counter() - t0\n","\n","            with tf.device('/CPU:0'):\n","                cpu_profiles = {\n","                    \"cpu_1\": np.array([time_examples(model, 1) for _ in range(n_runs)]).mean(),\n","                    \"cpu_10\": np.array([time_examples(model, 10) for _ in range(n_runs)]).mean(),\n","                    \"cpu_100\": np.array([time_examples(model, 100) for _ in range(n_runs)]).mean()\n","                }\n","\n","            with tf.device('/GPU:0'):\n","                gpu_profiles = {\n","                    \"gpu_1\": np.array([time_examples(model, 1) for _ in range(n_runs)]).mean(),\n","                    \"gpu_10\": np.array([time_examples(model, 10) for _ in range(n_runs)]).mean(),\n","                    \"gpu_100\": np.array([time_examples(model, 100) for _ in range(n_runs)]).mean()\n","                }\n","\n","            # Get number of parameters\n","            params_counts = {\n","                \"trainable_params\": np.sum([K.count_params(w) for w in model.trainable_weights]),\n","                \"non_trainable_params\": np.sum([K.count_params(w) for w in model.non_trainable_weights])\n","            }\n","            params_counts[\"total_params\"] = params_counts[\"trainable_params\"] + params_counts[\"non_trainable_params\"]\n","\n","            # Generate evaluation metrics for validation and test set\n","            final_metrics_val = model.evaluate(val_dataset, return_dict=True)\n","            final_metrics_val = {f\"final_val_{k}\": v for k, v in final_metrics_val.items()}\n","            final_metrics_test = model.evaluate(test_dataset, return_dict=True)\n","            final_metrics_test = {f\"final_test_{k}\": v for k, v in final_metrics_test.items()}\n","\n","            # Generate Dataframe and export to parquet\n","            logs_params = {\n","                **params,\n","                **hparams,\n","                **history.params,\n","                **cpu_profiles,\n","                **gpu_profiles,\n","                **params_counts,\n","                **final_metrics_val,\n","                **final_metrics_test\n","            }\n","            logs_df = pd.DataFrame({**history.history, \"epoch\": history.epoch})\n","            for param, value in logs_params.items():\n","                logs_df[param] = value\n","            logs_df.to_parquet(os.path.join(target_dir, f\"{model_name}.parquet\"))\n","\n","            # Dump all parameters and metadata to .json file\n","            with open(os.path.join(target_dir, 'model_details.json'), 'w') as f:\n","                json.dump(logs_params, f, cls=NpEncoder, indent=4)\n","\n","            def _convert_model(model, subdir=\"model\"):\n","                # Create subdirectory\n","                subdir_path = os.path.join(target_dir, subdir)\n","                !mkdir -p {subdir_path}\n","\n","                # Write model summary to file\n","                model_summary_path = os.path.join(subdir_path, \"model_summary.txt\")\n","                with open(model_summary_path, 'w') as model_summary:\n","                    with redirect_stdout(model_summary):\n","                        model.summary()\n","\n","                # Export model summary as image\n","                model_summary_img_path = os.path.join(subdir_path, \"model_summary.png\")\n","                tf.keras.utils.plot_model(model, to_file=model_summary_img_path, show_shapes=True)\n","\n","                # Generate model paths\n","                keras_model_path = os.path.join(subdir_path, \"keras_model.h5\")\n","                saved_model_path = os.path.join(subdir_path, \"saved_model\")\n","                tfjs_layers_model_path = os.path.join(subdir_path, \"tfjs_layers_model\")\n","                tfjs_graph_model_path = os.path.join(subdir_path, \"tfjs_graph_model\")\n","\n","                # Save and convert model\n","                model.save(keras_model_path)\n","                tf.saved_model.save(model, saved_model_path)\n","                !tensorflowjs_converter --input_format=keras --output_format=tfjs_layers_model {keras_model_path} {tfjs_layers_model_path}\n","                !tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model {saved_model_path} {tfjs_graph_model_path}\n","            \n","            # Convert full model\n","            _convert_model(model, subdir=\"model\")\n","\n","            if n_prep_layers is not None:\n","                model_1 = tf.keras.Sequential(model.layers[:n_prep_layers])\n","                model_1.build(input_shape=input_shape)\n","                \n","                model_2 = tf.keras.Sequential(model.layers[n_prep_layers:])\n","                model_2.build(input_shape=model_1.layers[-1].output_shape)\n","\n","                # Convert models\n","                _convert_model(model_1, subdir=\"submodel_1\")\n","                _convert_model(model_2, subdir=\"submodel_2\")\n","\n","            # Compress TensorBoard logs\n","            model_log_dir = os.path.join(LOG_DIR, model_name)\n","            tensorboard_logs_path = os.path.join(target_dir, f\"{model_name}.tar.gz\")\n","            _under(model_log_dir, tensorboard_logs_path)\n","\n","    # Upload logs to GCS\n","    _under(target_dir, f\"gs://marvin-voice/models/{model_type}/{model_name}\", auth_on_upload=False)\n","    return logs_df"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |█████▎                          | 10kB 28.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20kB 17.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30kB 22.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40kB 20.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 51kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 61kB 10.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.1MB/s \n","\u001b[?25h\u001b[?25l\r\u001b[K     |███▏                            | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 20kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 102kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 8.5MB/s \n","\u001b[?25h  Building wheel for linkheader (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lApr2AmG3-Gw","cellView":"both","executionInfo":{"status":"ok","timestamp":1605061543619,"user_tz":-60,"elapsed":19447,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"10134628738205138361"}},"outputId":"697821a3-d1de-46ad-96c8-49aca4fc8415","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Download git repository\n","import os\n","if not os.getcwd().endswith(\"marvin-models\"):\n","    !git config --global user.email \"patrikkja@gmail.com\"\n","    !git config --global user.name \"Patrik Kjærran\"\n","    !git clone -q https://github.com/patrikkj/marvin-models.git\n","    %cd marvin-models\n","\n","# Internal modules\n","import io, sys, glob, time\n","from datetime import datetime\n","from importlib import reload\n","\n","# External modules\n","!pip install -q pydub\n","!pip install -q tensorflow-io\n","#!pip install -q -U tensorboard_plugin_profile\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import tensorflow_io as tfio\n","import tensorflow_addons as tfa\n","from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, LearningRateScheduler\n","from tensorboard.plugins.hparams import api as hp\n","\n","# Colab modules\n","from google.colab import auth\n","from IPython import display\n","    \n","# Scripts (record_audio requires pydub installed)\n","import scripts\n","\n","# Set random number generation seeds\n","np.random.seed(1)\n","tf.random.set_seed(1)\n","\n","# Enable logging to GitHub release tag\n","_set_gh_token(GH_TOKEN)\n","\n","# Set logging level\n","!mkdir -p {LOG_DIR}\n","tf.get_logger().setLevel(LOG_LEVEL)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/marvin-models\n","\u001b[K     |████████████████████████████████| 22.4MB 1.5MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TmjrsRGd4soU"},"source":["##### Download dataset\n"]},{"cell_type":"code","metadata":{"id":"wkUPW24VxvwH","cellView":"both","executionInfo":{"status":"ok","timestamp":1605061575028,"user_tz":-60,"elapsed":48737,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"10134628738205138361"}},"outputId":"3efd72df-a51b-425e-a205-3f76c73b4b59","colab":{"base_uri":"https://localhost:8080/"}},"source":["if 'arrays' not in globals():\n","    arrays = _from_gh(\"patrikkj\", \"marvin-models\", params['dataset'])\n","    pos_data, pos_labels = arrays['pos_data'], arrays['pos_labels']\n","    neg_data, neg_labels = arrays['neg_data'], arrays['neg_labels']\n","\n","    # Dataset characteristics\n","    classes = np.array([0, 1])\n","    split = [params['train_split'], params['val_split'], params['test_split']]\n","\n","    # Build dataset\n","    arrays, info = scripts.datasets.build_dataset(pos_data, pos_labels, neg_data, neg_labels, split)\n","    TRAIN_SIZE, VAL_SIZE, TEST_SIZE = info\n","    POS_SIZE = pos_data.shape[0]\n","    NEG_SIZE = neg_data.shape[0]\n","    TOTAL_SIZE = POS_SIZE + NEG_SIZE"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading dataset in parallell ... \tdone! (29.484 seconds)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fp_v3dDTX9fM"},"source":["##### Build TensorFlow graph\n"]},{"cell_type":"code","metadata":{"id":"xvKxVTrGdrOc","cellView":"both","executionInfo":{"status":"ok","timestamp":1605061575029,"user_tz":-60,"elapsed":47128,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"10134628738205138361"}}},"source":["optimizers = {\n","    'adam': tf.keras.optimizers.Adam,\n","    'rmsprop': tf.keras.optimizers.RMSprop,\n","    'sgd': tf.keras.optimizers.SGD\n","}\n","\n","def build_model(params, hparams, output_bias):\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Input(shape=(params['sample_rate'],), dtype=tf.float32))\n","\n","    # Create preprocessing model\n","    preprocessing = tf.keras.Sequential([\n","        scripts.layers.Spectrogram(params, hparams),\n","        scripts.layers.MelSpectrogram(params, hparams),\n","        scripts.layers.LogMelSpectrogram(params, hparams),\n","    ], name=\"DataPreprocessing\")\n","    model.add(preprocessing)\n","\n","    # Create augmentation model\n","    augmentation = tf.keras.Sequential([\n","        scripts.layers.FrequencyMask(params, hparams),\n","        scripts.layers.TimeMask(params, hparams),\n","    ], name=\"DataAugmentation\")\n","    model.add(augmentation)\n","\n","    # Convolutional units\n","    conv_filters = hparams['conv_filters']\n","    for _ in range(hparams['conv_layers']):\n","        model.add(tf.keras.layers.Conv1D(conv_filters, hparams['conv_kernel_size'], strides=hparams['conv_stride'], activation='relu'))\n","        model.add(tf.keras.layers.BatchNormalization())\n","        model.add(tf.keras.layers.MaxPool1D(hparams['maxpool_size']))\n","        conv_filters *= 2\n","    model.add(tf.keras.layers.Flatten())\n","\n","    # Dense unit\n","    dense_units = hparams['dense_units']\n","    for _ in range(hparams['dense_layers']):\n","        model.add(tf.keras.layers.Dense(dense_units, activation='relu'))\n","        model.add(tf.keras.layers.Dropout(hparams['dropout'])) #noise_shape=(batch_size, 1, features)\n","        dense_units /= 2\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias))\n","    return model\n","\n","def train_model(params, hparams, metrics, log_dir, model_type, output_bias=None, **fit_kwargs):\n","    # Prepare output bias for imbalanced distributions\n","    if output_bias is not None:\n","        output_bias = None if output_bias == 0 else tf.keras.initializers.Constant(output_bias)\n","\n","    # Create callbacks and prepare logging\n","    early_stopping = EarlyStopping(patience=20, restore_best_weights=True)\n","    timestamp = datetime.now()\n","    dir_name = f\"{model_type}_{timestamp:%Y%m%d_%H%M%S}\"\n","    filename = f\"{log_dir}/{dir_name}\"\n","    hparams[\"__timestamp__\"] = int(f\"{timestamp:%Y%m%d%H%M%S}\")\n","    tensorboard = TensorBoard(filename, write_graph=False, histogram_freq=0, write_images=False) # profile_batch='50,70',\n","    hp_board = hp.KerasCallback(filename, hparams, trial_id=dir_name)\n","    callbacks = [tensorboard, hp_board, early_stopping]\n","\n","    # Build model and run\n","    model = build_model(params, hparams, output_bias)\n","    model.compile(optimizers[hparams['optimizer']](learning_rate=hparams['learning_rate']), 'binary_crossentropy', metrics)\n","    history = model.fit(callbacks=callbacks, **fit_kwargs)\n","    return model, history, dir_name"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0xEXMTa0bpn"},"source":["##### Define hyperparameter domains"]},{"cell_type":"code","metadata":{"cellView":"both","id":"IFGX4QkoLpqE","executionInfo":{"status":"ok","timestamp":1605061580508,"user_tz":-60,"elapsed":51443,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"10134628738205138361"}}},"source":["# Evaluation metrics\n","metrics = [tf.keras.metrics.Precision(name='precision'),\n","      tf.keras.metrics.Recall(name='recall'),\n","      tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n","      \n","hp_metrics = [hp.Metric('accuracy', display_name='Accuracy'),\n","    hp.Metric('precision', display_name='Precision'),\n","    hp.Metric('recall', display_name='Recall')]\n","\n","# Set hyperparameter domains\n","hparams_refs = {\n","    'pos_weight': hp.HParam('pos_weight', hp.Discrete([POS_SIZE/TOTAL_SIZE, 0.1, 0.2, 0.3, 0.4, 0.5])),\n","\n","    'frame_size': hp.HParam('frame_size', hp.Discrete([128, 256, 512, 1024])),\n","    'frame_step': hp.HParam('frame_step', hp.Discrete([128, 256, 512, 1024])),\n","    'fft_size': hp.HParam('fft_size', hp.Discrete([128, 256, 512, 1024, 2048])),\n","    'mel_bins': hp.HParam('melbins', hp.Discrete([16, 32, 64, 128])),\n","\n","    'max_time_mask': hp.HParam('max_time_mask', hp.IntInterval(10, 10)),\n","    'max_freq_mask': hp.HParam('max_freq_mask', hp.IntInterval(10, 10)),\n","\n","    'conv_layers': hp.HParam('conv_layers', hp.IntInterval(1, 4)),\n","    'conv_filters': hp.HParam('conv_filters', hp.Discrete([32, 64])),\n","    'conv_kernel_size': hp.HParam('conv_kernel_size', hp.Discrete([3, 5])),\n","    'conv_stride': hp.HParam('conv_stride', hp.Discrete([1, 2, 3])),\n","    'maxpool_size': hp.HParam('maxpool_size', hp.Discrete([1, 3, 5])),\n","    \n","    'dense_layers': hp.HParam('dense_layers', hp.IntInterval(1, 3)),\n","    'dense_units': hp.HParam('dense_units', hp.Discrete([64])),\n","    'dropout': hp.HParam('dropout', hp.RealInterval(0.1, 0.2)),\n","\n","    'batch_size': hp.HParam('batch_size', hp.Discrete([64, 128, 256])),\n","    'optimizer': hp.HParam('optimizer', hp.Discrete(['adam', 'rmsprop', 'sgd'])),\n","    'learning_rate': hp.HParam('learning_rate', hp.Discrete([10**-3.5, 10e-4, 10**-4.5])),\n","}\n","\n","# Hyperparameter constraints\n","constraints = {\n","    'frame_size': [lambda hparams: hparams['fft_size'] >= hparams['frame_size']],\n","    'frame_step': [lambda hparams: hparams['frame_size'] >= hparams['frame_step']],\n","}"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dKBuyErAtczt"},"source":["##### Random search"]},{"cell_type":"code","metadata":{"id":"o9YoHpScLpqL","executionInfo":{"status":"ok","timestamp":1605077571595,"user_tz":-60,"elapsed":16041620,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"10134628738205138361"}},"outputId":"30295b25-758e-4798-94b8-c0db12005587","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Random serach with parameter lock\n","hparams_locked = {\n","    # 'pos_weight': 0.5, \n","\n","    'frame_size': 512,\n","    'frame_step': 256,\n","    'fft_size': 512,\n","    'mel_bins': 64,\n","\n","    'max_time_mask': 10,\n","    'max_freq_mask': 10,\n","\n","    # 'conv_layers': 2,\n","    # 'conv_filters': 32,\n","    # 'conv_kernel_size': 3,\n","    # 'conv_stride': 1,\n","    # 'maxpool_size': 3,\n","    \n","    # 'dense_layers': 3,\n","    # 'dense_units': 64,\n","    # 'dropout': 0.1,\n","\n","    # 'batch_size': 128,\n","    'optimizer': 'adam',\n","    # 'learning_rate': 10e-4,\n","}\n","\n","NUM_ITERATIONS = 100\n","for i in range(NUM_ITERATIONS):\n","    hparams = {k: v.domain.sample_uniform() for k, v in hparams_refs.items() if k not in hparams_locked}\n","    hparams.update(hparams_locked)\n","\n","    # Assert that hyperparameter allocation is valid\n","    while True:\n","        for hparam, hparam_constraints in constraints.items():\n","            # Reallocate invalid hyperparameters\n","            if not all(constraint(hparams) for constraint in hparam_constraints):\n","                hparams[hparam] = hparams_refs[hparam].domain.sample_uniform()\n","                break\n","        else: # If all allocations are valid, break out of while loop\n","            break\n","\n","    try:\n","        # Build datasets\n","        datasets = scripts.datasets.resample_dataset(arrays, hparams['batch_size'], hparams['pos_weight'])\n","        train_dataset, val_dataset, test_dataset = datasets\n","        output_bias = np.log([hparams['pos_weight']/(1-hparams['pos_weight'])])\n","        print(hparams)\n","        \n","        fit_kwargs = {\n","            \"x\": train_dataset,\n","            \"validation_data\": val_dataset,\n","            \"epochs\": 200,\n","            \"steps_per_epoch\": TRAIN_SIZE // hparams[\"batch_size\"],\n","            \"verbose\": 0\n","        }\n","        model, history, model_name = train_model(params, hparams, metrics, log_dir=LOG_DIR, model_type=MODEL_TYPE, output_bias=output_bias, **fit_kwargs)\n","        _export_model(model, model_name, MODEL_TYPE, val_dataset, test_dataset, params, hparams, history, LOG_DIR, n_prep_layers=2)\n","    except Exception as e:\n","        print(e)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["{'pos_weight': 0.5, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.1046956511787766, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d_2/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_2/conv1d/ExpandDims, conv1d_2/conv1d/ExpandDims_1)' with input shapes: [?,1,1,64], [1,3,64,128].\n","{'pos_weight': 0.2, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.167580320832979, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_022620    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_022620\n","_export_model: 35.27947904 s\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 3, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.19777057752062716, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node max_pooling1d_5/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 3, 1, 1], padding=\"VALID\", strides=[1, 3, 1, 1]](max_pooling1d_5/ExpandDims)' with input shapes: [?,1,1,128].\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.12887104525752663, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_023456    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_023456\n","_export_model: 35.56703043 s\n","{'pos_weight': 0.5, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.1540363497572228, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_11/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_11/conv1d/ExpandDims, conv1d_11/conv1d/ExpandDims_1)' with input shapes: [?,1,3,64], [1,5,64,128].\n","{'pos_weight': 0.1, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18749872035728662, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d_14/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 2, 1], use_cudnn_on_gpu=true](conv1d_14/conv1d/ExpandDims, conv1d_14/conv1d/ExpandDims_1)' with input shapes: [?,1,1,128], [1,3,128,256].\n","{'pos_weight': 0.1, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.11598686403112818, 'batch_size': 128, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_023726    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_023726\n","_export_model: 31.48210780 s\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.11063904091808234, 'batch_size': 64, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_024044    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_024044\n","_export_model: 32.41223960 s\n","{'pos_weight': 0.1, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.13115968774232833, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_024704    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_024704\n","_export_model: 35.60251265 s\n","{'pos_weight': 0.5, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.19821105807310885, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_025742    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_025742\n","_export_model: 32.12180159 s\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.17960493234933925, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 2 for '{{node max_pooling1d_19/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_19/ExpandDims)' with input shapes: [?,2,1,128].\n","{'pos_weight': 0.1, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.1903628876656974, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_030051    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_030051\n","_export_model: 32.43957841 s\n","{'pos_weight': 0.5, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.15240301755033805, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_22/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_22/ExpandDims)' with input shapes: [?,1,1,64].\n","{'pos_weight': 0.4, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.14324319159371574, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_030749    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_030749\n","_export_model: 35.31331029 s\n","{'pos_weight': 0.4, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.13345663811087674, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_031017    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_031017\n","_export_model: 36.13506007 s\n","{'pos_weight': 0.1, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.19949700797946654, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_031359    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_031359\n","_export_model: 32.47939403 s\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.11707624615049449, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_031826    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_031826\n","_export_model: 34.59946308 s\n","{'pos_weight': 0.4, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.1282782579860044, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_032045    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_032045\n","_export_model: 32.22514354 s\n","{'pos_weight': 0.1, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.12051198772589566, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_032321    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_032321\n","_export_model: 33.19403539 s\n","{'pos_weight': 0.4, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.16791278749959077, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_033252    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_033252\n","_export_model: 31.97286796 s\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.15790647371247765, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_033638    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_033638\n","_export_model: 34.09363423 s\n","{'pos_weight': 0.4, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.11775549919548133, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_034041    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_034041\n","_export_model: 33.70722319 s\n","{'pos_weight': 0.1, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.16101139113007698, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_035016    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_035016\n","_export_model: 33.21706371 s\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.1919523192335901, 'batch_size': 64, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node conv1d_45/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_45/conv1d/ExpandDims, conv1d_45/conv1d/ExpandDims_1)' with input shapes: [?,1,1,128], [1,5,128,256].\n","{'pos_weight': 0.4, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.16301081096589654, 'batch_size': 64, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_035504    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_035504\n","_export_model: 33.34690819 s\n","{'pos_weight': 0.2, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.15089099967236316, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_040157    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_040157\n","_export_model: 33.05407718 s\n","{'pos_weight': 0.1, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.15826410675549302, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_040518    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_040518\n","_export_model: 35.47923688 s\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.12068757937077448, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 2 for '{{node max_pooling1d_48/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 3, 1, 1], padding=\"VALID\", strides=[1, 3, 1, 1]](max_pooling1d_48/ExpandDims)' with input shapes: [?,2,1,64].\n","{'pos_weight': 0.1, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.11107737976469292, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_54/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_54/conv1d/ExpandDims, conv1d_54/conv1d/ExpandDims_1)' with input shapes: [?,1,3,32], [1,5,32,64].\n","{'pos_weight': 0.4, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.17155877756571872, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_040834    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_040834\n","_export_model: 34.18309397 s\n","{'pos_weight': 0.3, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.11545693783170308, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_041212    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_041212\n","_export_model: 33.53965453 s\n","{'pos_weight': 0.3, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.1641778148718629, 'batch_size': 64, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node conv1d_61/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 2, 1], use_cudnn_on_gpu=true](conv1d_61/conv1d/ExpandDims, conv1d_61/conv1d/ExpandDims_1)' with input shapes: [?,1,1,128], [1,5,128,256].\n","{'pos_weight': 0.2, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.16162786586895658, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_041438    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_041438\n","_export_model: 31.85958363 s\n","{'pos_weight': 0.1, 'conv_layers': 4, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.15539934323484073, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_58/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_58/ExpandDims)' with input shapes: [?,1,1,64].\n","{'pos_weight': 0.5, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.17195595319083218, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_041747    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_041747\n","_export_model: 34.30277220 s\n","{'pos_weight': 0.1, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.16223804502684375, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_042401    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_042401\n","_export_model: 33.52714875 s\n","{'pos_weight': 0.1, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.1961606364668287, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_042929    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_042929\n","_export_model: 32.58669800 s\n","{'pos_weight': 0.1, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.19633109725864412, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_043127    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_043127\n","_export_model: 34.75360585 s\n","{'pos_weight': 0.4, 'conv_layers': 4, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.1021645046606797, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 2 for '{{node max_pooling1d_68/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 3, 1, 1], padding=\"VALID\", strides=[1, 3, 1, 1]](max_pooling1d_68/ExpandDims)' with input shapes: [?,2,1,64].\n","{'pos_weight': 0.5, 'conv_layers': 4, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.17394941515621493, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d_78/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_78/conv1d/ExpandDims, conv1d_78/conv1d/ExpandDims_1)' with input shapes: [?,1,1,128], [1,3,128,256].\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.12955002133923826, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_73/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_73/ExpandDims)' with input shapes: [?,1,1,128].\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.10798759724256025, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node conv1d_83/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 2, 1], use_cudnn_on_gpu=true](conv1d_83/conv1d/ExpandDims, conv1d_83/conv1d/ExpandDims_1)' with input shapes: [?,1,1,128], [1,5,128,256].\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18612506106470791, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_043518    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_043518\n","_export_model: 35.66999926 s\n","{'pos_weight': 0.2, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.1542746206489519, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_043825    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_043825\n","_export_model: 33.21955837 s\n","{'pos_weight': 0.5, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.1827323706122865, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_044742    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_044742\n","_export_model: 34.16406137 s\n","{'pos_weight': 0.3, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.12232018593753528, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_045804    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_045804\n","_export_model: 33.97286683 s\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18265944680110452, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node conv1d_93/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_93/conv1d/ExpandDims, conv1d_93/conv1d/ExpandDims_1)' with input shapes: [?,1,1,64], [1,5,64,128].\n","{'pos_weight': 0.5, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.1434800006296576, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_86/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_86/ExpandDims)' with input shapes: [?,1,1,128].\n","{'pos_weight': 0.5, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 3, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.15473912067297363, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 2 for '{{node max_pooling1d_88/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 3, 1, 1], padding=\"VALID\", strides=[1, 3, 1, 1]](max_pooling1d_88/ExpandDims)' with input shapes: [?,2,1,64].\n","{'pos_weight': 0.1, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.16502083846047352, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 2 for '{{node max_pooling1d_90/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_90/ExpandDims)' with input shapes: [?,2,1,128].\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.1770916524090625, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_050636    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_050636\n","_export_model: 32.63780933 s\n","{'pos_weight': 0.4, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.12110178534585958, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_93/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_93/ExpandDims)' with input shapes: [?,1,1,64].\n","{'pos_weight': 0.2, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.15793959185307688, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_104/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_104/conv1d/ExpandDims, conv1d_104/conv1d/ExpandDims_1)' with input shapes: [?,1,3,64], [1,5,64,128].\n","{'pos_weight': 0.4, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.19996377477238728, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_106/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_106/conv1d/ExpandDims, conv1d_106/conv1d/ExpandDims_1)' with input shapes: [?,1,3,64], [1,5,64,128].\n","{'pos_weight': 0.1, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.1577537090985805, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_97/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_97/ExpandDims)' with input shapes: [?,1,1,128].\n","{'pos_weight': 0.1, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.15447194095922595, 'batch_size': 128, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_051442    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_051442\n","_export_model: 34.12003316 s\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.1386135652314759, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_051804    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_051804\n","_export_model: 36.07835839 s\n","{'pos_weight': 0.2, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.11488054671039119, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_052117    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_052117\n","_export_model: 34.10091023 s\n","{'pos_weight': 0.3, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.19751103976985507, 'batch_size': 128, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 2 for '{{node max_pooling1d_106/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_106/ExpandDims)' with input shapes: [?,2,1,128].\n","{'pos_weight': 0.4, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18743552655291776, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_052458    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_052458\n","_export_model: 32.10849547 s\n","{'pos_weight': 0.2, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.1422713233720808, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 2 for '{{node conv1d_122/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_122/conv1d/ExpandDims, conv1d_122/conv1d/ExpandDims_1)' with input shapes: [?,1,2,256], [1,3,256,512].\n","{'pos_weight': 0.1, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.140570742902589, 'batch_size': 64, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node max_pooling1d_113/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 3, 1, 1], padding=\"VALID\", strides=[1, 3, 1, 1]](max_pooling1d_113/ExpandDims)' with input shapes: [?,1,1,256].\n","{'pos_weight': 0.5, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18244782409962354, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_053358    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_053358\n","_export_model: 32.17212506 s\n","{'pos_weight': 0.4, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.12621393279922974, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d_129/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_129/conv1d/ExpandDims, conv1d_129/conv1d/ExpandDims_1)' with input shapes: [?,1,1,64], [1,3,64,128].\n","{'pos_weight': 0.4, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.13457997616337192, 'batch_size': 64, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d_133/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_133/conv1d/ExpandDims, conv1d_133/conv1d/ExpandDims_1)' with input shapes: [?,1,1,256], [1,3,256,512].\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 4, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18507364000336873, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node conv1d_136/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_136/conv1d/ExpandDims, conv1d_136/conv1d/ExpandDims_1)' with input shapes: [?,1,1,64], [1,5,64,128].\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.10341443213802763, 'batch_size': 128, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 2 for '{{node max_pooling1d_123/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_123/ExpandDims)' with input shapes: [?,2,1,128].\n","{'pos_weight': 0.5, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.18632978392623245, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_053609    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_053609\n","_export_model: 33.88178397 s\n","{'pos_weight': 0.4, 'conv_layers': 4, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.1516642721642893, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node conv1d_144/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_144/conv1d/ExpandDims, conv1d_144/conv1d/ExpandDims_1)' with input shapes: [?,1,1,128], [1,5,128,256].\n","{'pos_weight': 0.5, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18358498411271143, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_146/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_146/conv1d/ExpandDims, conv1d_146/conv1d/ExpandDims_1)' with input shapes: [?,1,3,32], [1,5,32,64].\n","{'pos_weight': 0.5, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.19076028477858523, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_053840    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_053840\n","_export_model: 36.21928436 s\n","{'pos_weight': 0.2, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.18908565508866312, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_134/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_134/ExpandDims)' with input shapes: [?,1,1,128].\n","{'pos_weight': 0.4, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 3, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.1866659166995714, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node max_pooling1d_136/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 3, 1, 1], padding=\"VALID\", strides=[1, 3, 1, 1]](max_pooling1d_136/ExpandDims)' with input shapes: [?,1,1,64].\n","{'pos_weight': 0.2, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.17022660241450616, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_054502    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_054502\n","_export_model: 32.74700414 s\n","{'pos_weight': 0.2, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.17857724300510233, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_139/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_139/ExpandDims)' with input shapes: [?,1,1,64].\n","{'pos_weight': 0.5, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.14909638860294058, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_055039    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_055039\n","_export_model: 33.32435260 s\n","{'pos_weight': 0.4, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.18771807216020125, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_055748    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_055748\n","_export_model: 36.40903098 s\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.1956973751828373, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_060303    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_060303\n","_export_model: 39.22433021 s\n","{'pos_weight': 0.2, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.10671501671853137, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_060843    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_060843\n","_export_model: 35.09466528 s\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 4, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.18612191048929935, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 2 for '{{node max_pooling1d_148/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_148/ExpandDims)' with input shapes: [?,2,1,64].\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 4, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.1271560441542996, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_167/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_167/conv1d/ExpandDims, conv1d_167/conv1d/ExpandDims_1)' with input shapes: [?,1,3,32], [1,5,32,64].\n","{'pos_weight': 0.4, 'conv_layers': 2, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.10273905441201188, 'batch_size': 64, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_061502    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_061502\n","_export_model: 35.67964760 s\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.12453229957078923, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_171/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_171/conv1d/ExpandDims, conv1d_171/conv1d/ExpandDims_1)' with input shapes: [?,1,3,64], [1,5,64,128].\n","{'pos_weight': 0.4, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.1536430126571163, 'batch_size': 64, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_154/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_154/ExpandDims)' with input shapes: [?,1,1,64].\n","{'pos_weight': 0.2, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.11467935369362675, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_061845    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_061845\n","_export_model: 35.88065488 s\n","{'pos_weight': 0.2, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.11641557775938, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_062513    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_062513\n","_export_model: 39.21306625 s\n","{'pos_weight': 0.1, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.170517698356538, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_180/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_180/conv1d/ExpandDims, conv1d_180/conv1d/ExpandDims_1)' with input shapes: [?,1,3,64], [1,5,64,128].\n","{'pos_weight': 0.5, 'conv_layers': 3, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18568041123538942, 'batch_size': 128, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 3 for '{{node conv1d_182/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_182/conv1d/ExpandDims, conv1d_182/conv1d/ExpandDims_1)' with input shapes: [?,1,3,64], [1,5,64,128].\n","{'pos_weight': 0.1, 'conv_layers': 4, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.19969260920258627, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 2 for '{{node max_pooling1d_163/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_163/ExpandDims)' with input shapes: [?,2,1,128].\n","{'pos_weight': 0.1, 'conv_layers': 1, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.17988012636079062, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_062759    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_062759\n","_export_model: 34.97059415 s\n","{'pos_weight': 0.5, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.191245309775856, 'batch_size': 64, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_166/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_166/ExpandDims)' with input shapes: [?,1,1,128].\n","{'pos_weight': 0.3, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 3, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.10932137654782773, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node max_pooling1d_168/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 3, 1, 1], padding=\"VALID\", strides=[1, 3, 1, 1]](max_pooling1d_168/ExpandDims)' with input shapes: [?,1,1,64].\n","{'pos_weight': 0.05253655894565806, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.1876964026411732, 'batch_size': 128, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node max_pooling1d_170/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_170/ExpandDims)' with input shapes: [?,1,1,64].\n","{'pos_weight': 0.1, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 5, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.16076699991911034, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 2 for '{{node max_pooling1d_172/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 1, 1], padding=\"VALID\", strides=[1, 5, 1, 1]](max_pooling1d_172/ExpandDims)' with input shapes: [?,2,1,128].\n","{'pos_weight': 0.1, 'conv_layers': 4, 'conv_filters': 32, 'conv_kernel_size': 5, 'conv_stride': 3, 'maxpool_size': 1, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.18897725691576794, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 5 from 1 for '{{node conv1d_197/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 3, 1], use_cudnn_on_gpu=true](conv1d_197/conv1d/ExpandDims, conv1d_197/conv1d/ExpandDims_1)' with input shapes: [?,1,1,128], [1,5,128,256].\n","{'pos_weight': 0.2, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.12387017287920743, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d_200/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_200/conv1d/ExpandDims, conv1d_200/conv1d/ExpandDims_1)' with input shapes: [?,1,1,64], [1,3,64,128].\n","{'pos_weight': 0.1, 'conv_layers': 2, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 1, 'dense_units': 64, 'dropout': 0.19191596566381672, 'batch_size': 256, 'learning_rate': 0.001, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_063110    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_063110\n","_export_model: 35.83070950 s\n","{'pos_weight': 0.4, 'conv_layers': 3, 'conv_filters': 32, 'conv_kernel_size': 3, 'conv_stride': 1, 'maxpool_size': 3, 'dense_layers': 3, 'dense_units': 64, 'dropout': 0.17591342234459204, 'batch_size': 256, 'learning_rate': 0.00031622776601683794, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_063430    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_063430\n","_export_model: 38.42959033 s\n","{'pos_weight': 0.5, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 5, 'conv_stride': 1, 'maxpool_size': 5, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.17668703101375707, 'batch_size': 64, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_063804    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_063804\n","_export_model: 34.57241719 s\n","{'pos_weight': 0.5, 'conv_layers': 1, 'conv_filters': 64, 'conv_kernel_size': 3, 'conv_stride': 2, 'maxpool_size': 1, 'dense_layers': 2, 'dense_units': 64, 'dropout': 0.12431507736265154, 'batch_size': 256, 'learning_rate': 3.1622776601683795e-05, 'frame_size': 512, 'frame_step': 256, 'fft_size': 512, 'mel_bins': 64, 'max_time_mask': 10, 'max_freq_mask': 10, 'optimizer': 'adam'}\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201111_064545    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201111_064545\n","_export_model: 34.01033336 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B2sPU8sdppj4"},"source":["##### Single iteration https://bit.ly/34Z2pDM"]},{"cell_type":"code","metadata":{"cellView":"both","id":"eWCh5PcULpqH","executionInfo":{"status":"ok","timestamp":1604896260084,"user_tz":-60,"elapsed":111388,"user":{"displayName":"1Patrik Kjærran","photoUrl":"","userId":"16440498798423018427"}},"outputId":"72d57239-acf0-4c55-b883-ec7209006cb2","colab":{"base_uri":"https://localhost:8080/","height":299}},"source":["# Set hyperparameters\n","hparams = {\n","    'pos_weight': 0.5, \n","\n","    'frame_size': 512,\n","    'frame_step': 256,\n","    'fft_size': 512,\n","    'mel_bins': 64,\n","\n","    'max_time_mask': 10,\n","    'max_freq_mask': 10,\n","\n","    'conv_layers': 2,\n","    'conv_filters': 32,\n","    'conv_kernel_size': 3,\n","    'conv_stride': 1,\n","    'maxpool_size': 3,\n","    \n","    'dense_layers': 3,\n","    'dense_units': 64,\n","    'dropout': 0.1,\n","\n","    'batch_size': 128,\n","    'optimizer': 'adam',\n","    'learning_rate': 10e-4,\n","}\n","\n","# Build datasets\n","datasets = scripts.datasets.resample_dataset(arrays, hparams['batch_size'], hparams['pos_weight'])\n","train_dataset, val_dataset, test_dataset = datasets\n","output_bias = np.log([hparams['pos_weight']/(1-hparams['pos_weight'])])\n","\n","fit_kwargs = {\n","    \"x\": train_dataset,\n","    \"validation_data\": val_dataset,\n","    \"epochs\": 3,\n","    \"steps_per_epoch\": TRAIN_SIZE // hparams[\"batch_size\"],\n","    \"verbose\": 1\n","}\n","model, history, model_name = train_model(params, hparams, metrics, log_dir=LOG_DIR, model_type=MODEL_TYPE, output_bias=output_bias, **fit_kwargs)\n","_export_model(model, model_name, MODEL_TYPE, val_dataset, test_dataset, params, hparams, history, LOG_DIR, n_prep_layers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","155/155 [==============================] - 4s 26ms/step - loss: 0.4378 - precision: 0.7743 - recall: 0.8197 - accuracy: 0.7903 - val_loss: 0.1842 - val_precision: 0.4583 - val_recall: 0.8023 - val_accuracy: 0.9398\n","Epoch 2/3\n","155/155 [==============================] - 3s 21ms/step - loss: 0.2150 - precision: 0.9097 - recall: 0.9204 - accuracy: 0.9147 - val_loss: 0.1507 - val_precision: 0.4501 - val_recall: 0.9427 - val_accuracy: 0.9365\n","Epoch 3/3\n","155/155 [==============================] - 3s 21ms/step - loss: 0.1450 - precision: 0.9421 - recall: 0.9481 - accuracy: 0.9451 - val_loss: 0.0904 - val_precision: 0.6052 - val_recall: 0.9398 - val_accuracy: 0.9646\n","UPLOADING DIR (1/1)    from    /tmp/models/cnn_fft/cnn_fft_20201109_042957    to    gs://marvin-voice/models/cnn_fft/cnn_fft_20201109_042957\n","_export_model: 38.72986013 s\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>accuracy</th>\n","      <th>val_loss</th>\n","      <th>val_precision</th>\n","      <th>val_recall</th>\n","      <th>val_accuracy</th>\n","      <th>epoch</th>\n","      <th>dataset</th>\n","      <th>train_split</th>\n","      <th>val_split</th>\n","      <th>test_split</th>\n","      <th>sample_rate</th>\n","      <th>min_freq</th>\n","      <th>max_freq</th>\n","      <th>pos_weight</th>\n","      <th>frame_size</th>\n","      <th>frame_step</th>\n","      <th>fft_size</th>\n","      <th>mel_bins</th>\n","      <th>max_time_mask</th>\n","      <th>max_freq_mask</th>\n","      <th>conv_layers</th>\n","      <th>conv_filters</th>\n","      <th>conv_kernel_size</th>\n","      <th>conv_stride</th>\n","      <th>maxpool_size</th>\n","      <th>dense_layers</th>\n","      <th>dense_units</th>\n","      <th>dropout</th>\n","      <th>batch_size</th>\n","      <th>optimizer</th>\n","      <th>learning_rate</th>\n","      <th>__timestamp__</th>\n","      <th>verbose</th>\n","      <th>epochs</th>\n","      <th>steps</th>\n","      <th>cpu_1</th>\n","      <th>cpu_10</th>\n","      <th>cpu_100</th>\n","      <th>gpu_1</th>\n","      <th>gpu_10</th>\n","      <th>gpu_100</th>\n","      <th>trainable_params</th>\n","      <th>non_trainable_params</th>\n","      <th>total_params</th>\n","      <th>final_val_loss</th>\n","      <th>final_val_precision</th>\n","      <th>final_val_recall</th>\n","      <th>final_val_accuracy</th>\n","      <th>final_test_loss</th>\n","      <th>final_test_precision</th>\n","      <th>final_test_recall</th>\n","      <th>final_test_accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.437767</td>\n","      <td>0.774267</td>\n","      <td>0.819748</td>\n","      <td>0.790272</td>\n","      <td>0.184206</td>\n","      <td>0.458265</td>\n","      <td>0.802292</td>\n","      <td>0.939822</td>\n","      <td>0</td>\n","      <td>dataset_half_notrim_tensors</td>\n","      <td>0.6</td>\n","      <td>0.2</td>\n","      <td>0.2</td>\n","      <td>16000</td>\n","      <td>0</td>\n","      <td>8000</td>\n","      <td>0.5</td>\n","      <td>512</td>\n","      <td>256</td>\n","      <td>512</td>\n","      <td>64</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>64</td>\n","      <td>0.1</td>\n","      <td>128</td>\n","      <td>adam</td>\n","      <td>0.001</td>\n","      <td>20201109042957</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>155</td>\n","      <td>0.100306</td>\n","      <td>0.063504</td>\n","      <td>0.349848</td>\n","      <td>0.048059</td>\n","      <td>0.033422</td>\n","      <td>0.050523</td>\n","      <td>35745</td>\n","      <td>192</td>\n","      <td>35937</td>\n","      <td>0.090368</td>\n","      <td>0.605166</td>\n","      <td>0.939828</td>\n","      <td>0.964646</td>\n","      <td>0.088195</td>\n","      <td>0.620112</td>\n","      <td>0.954155</td>\n","      <td>0.966897</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.214958</td>\n","      <td>0.909672</td>\n","      <td>0.920420</td>\n","      <td>0.914667</td>\n","      <td>0.150698</td>\n","      <td>0.450068</td>\n","      <td>0.942693</td>\n","      <td>0.936513</td>\n","      <td>1</td>\n","      <td>dataset_half_notrim_tensors</td>\n","      <td>0.6</td>\n","      <td>0.2</td>\n","      <td>0.2</td>\n","      <td>16000</td>\n","      <td>0</td>\n","      <td>8000</td>\n","      <td>0.5</td>\n","      <td>512</td>\n","      <td>256</td>\n","      <td>512</td>\n","      <td>64</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>64</td>\n","      <td>0.1</td>\n","      <td>128</td>\n","      <td>adam</td>\n","      <td>0.001</td>\n","      <td>20201109042957</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>155</td>\n","      <td>0.100306</td>\n","      <td>0.063504</td>\n","      <td>0.349848</td>\n","      <td>0.048059</td>\n","      <td>0.033422</td>\n","      <td>0.050523</td>\n","      <td>35745</td>\n","      <td>192</td>\n","      <td>35937</td>\n","      <td>0.090368</td>\n","      <td>0.605166</td>\n","      <td>0.939828</td>\n","      <td>0.964646</td>\n","      <td>0.088195</td>\n","      <td>0.620112</td>\n","      <td>0.954155</td>\n","      <td>0.966897</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.144968</td>\n","      <td>0.942064</td>\n","      <td>0.948072</td>\n","      <td>0.945111</td>\n","      <td>0.090368</td>\n","      <td>0.605166</td>\n","      <td>0.939828</td>\n","      <td>0.964646</td>\n","      <td>2</td>\n","      <td>dataset_half_notrim_tensors</td>\n","      <td>0.6</td>\n","      <td>0.2</td>\n","      <td>0.2</td>\n","      <td>16000</td>\n","      <td>0</td>\n","      <td>8000</td>\n","      <td>0.5</td>\n","      <td>512</td>\n","      <td>256</td>\n","      <td>512</td>\n","      <td>64</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>64</td>\n","      <td>0.1</td>\n","      <td>128</td>\n","      <td>adam</td>\n","      <td>0.001</td>\n","      <td>20201109042957</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>155</td>\n","      <td>0.100306</td>\n","      <td>0.063504</td>\n","      <td>0.349848</td>\n","      <td>0.048059</td>\n","      <td>0.033422</td>\n","      <td>0.050523</td>\n","      <td>35745</td>\n","      <td>192</td>\n","      <td>35937</td>\n","      <td>0.090368</td>\n","      <td>0.605166</td>\n","      <td>0.939828</td>\n","      <td>0.964646</td>\n","      <td>0.088195</td>\n","      <td>0.620112</td>\n","      <td>0.954155</td>\n","      <td>0.966897</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       loss  precision  ...  final_test_recall  final_test_accuracy\n","0  0.437767   0.774267  ...           0.954155             0.966897\n","1  0.214958   0.909672  ...           0.954155             0.966897\n","2  0.144968   0.942064  ...           0.954155             0.966897\n","\n","[3 rows x 55 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"8FWj6aZZirUD"},"source":["##### Test model on custom input and visualize"]},{"cell_type":"code","metadata":{"cellView":"form","id":"Xxhd7kXblNWo"},"source":["#@title Marvin! &#128039;&#128039;&#128039;\n","duration = 6 #@param {type:\"slider\", min:1, max:10, step:1}\n","audio = scripts.record_audio.record(duration)\n","desired_sample_rate = 16_000\n","sample_rate = audio.frame_rate\n","raw_audio = audio.raw_data\n","stride_size = desired_sample_rate//5\n","threshold = 0.5\n","\n","tensor = tf.io.decode_raw(audio.raw_data, tf.int32, fixed_length=sample_rate*duration*audio.sample_width)\n","tensor = tf.cast(tensor, tf.float32)\n","tensor /= 32768.0**2\n","tensor = tfio.audio.resample(tensor, sample_rate, desired_sample_rate)\n","\n","# Generate sliding window dataset\n","audio_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n","    data=tensor, \n","    targets=None, \n","    sequence_length=desired_sample_rate, \n","    sequence_stride=stride_size, \n","    batch_size=1)\n","\n","# Model prediction\n","predictions = model.predict(audio_dataset)\n","is_marvins = predictions > threshold\n","clip_length = tensor.shape[0]\n","n_segments = predictions.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJE7JeDolNO7","cellView":"form"},"source":["#@title Plot entire waveform\n","def set_size(w,h, ax):\n","    if not ax: ax=plt.gca()\n","    l = ax.figure.subplotpars.left\n","    r = ax.figure.subplotpars.right\n","    t = ax.figure.subplotpars.top\n","    b = ax.figure.subplotpars.bottom\n","    figw = float(w)/(r-l)\n","    figh = float(h)/(t-b)\n","    ax.figure.set_size_inches(figw, figh)\n","\n","fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(24,3))\n","\n","# Create upper graph\n","ax1.plot(tensor.numpy(), color='white')\n","ax1.axis('off')\n","\n","# Create bubbles\n","x_shift = stride_size//2\n","x = np.linspace(x_shift, clip_length - stride_size//2, num=n_segments)\n","y = np.ones(n_segments)\n","colors = predictions\n","area = 100 + is_marvins * 500\n","num = 1\n","ax2.scatter(x, y, s=area, c=colors, alpha=0.9, cmap='RdYlGn')\n","ax2.axis('off')\n","set_size(24, 1, ax=ax2)\n","\n","# Plot figure\n","fig.tight_layout(rect=[0, 0, 1, 1])\n","plt.show()\n","plt.ioff()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8vCRB08U_5b8","cellView":"form"},"source":["#@title Plot segments\n","\n","\n","# Plot figure\n","FIG_WIDTH = 24\n","\n","fig, axes = plt.subplots(n_segments + 1, 2, figsize=(FIG_WIDTH, (n_segments + 1)*0.5), gridspec_kw={'width_ratios':[1,20]})\n","axes_flat = axes.flat\n","axes[0, 0].axis('off')\n","top_axis = axes[0, 1]\n","top_axis.plot(tensor.numpy(), color='white')\n","top_axis.axis('off')\n","top_axis.set_xbound(0, clip_length)\n","\n","def set_size(w,h, ax):\n","    if not ax: ax=plt.gca()\n","    l = ax.figure.subplotpars.left\n","    r = ax.figure.subplotpars.right\n","    t = ax.figure.subplotpars.top\n","    b = ax.figure.subplotpars.bottom\n","    figw = float(w)/(r-l)\n","    figh = float(h)/(t-b)\n","    ax.figure.set_size_inches(figw, figh)\n","\n","for i, item in enumerate(zip(audio_dataset, predictions)):\n","    audio, prediction = item\n","    dot_ax, ax = axes_flat[2*(i+1):2*(i+2)]\n","\n","    # Fetch data\n","    is_marvin = prediction > 0.5\n","    audio_data = audio.numpy().squeeze()\n","    x = np.arange(i*stride_size, i*stride_size + desired_sample_rate)\n","\n","    # Create bubble\n","    colors = predictions\n","    area = 500 #100 + is_marvins * 500\n","    dot_ax.scatter([0], [0], s=area, c=[prediction], alpha=0.9, cmap='RdYlGn', vmin=0, vmax=1, )\n","    dot_ax.set_xlim(-1, 1)\n","    dot_ax.axis('off')\n","    #set_size(1, 1, ax=dot_ax)\n","\n","    # Plot segment\n","    #set_size(FIG_WIDTH, 1*n_segments+1, ax)\n","    ax.plot(x, audio_data, color='green' if is_marvin else 'grey')\n","    ax.set_xbound(0, clip_length)\n","    ax.axis('off')\n","    ax.get_shared_x_axes().join(ax, top_axis)\n","fig.tight_layout(rect=[0, 0, 1, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Y45twpo8AVS","cellView":"form"},"source":["#@title  Plot detailed audio pairs\n","def set_size(w,h, ax):\n","    if not ax: ax=plt.gca()\n","    l = ax.figure.subplotpars.left\n","    r = ax.figure.subplotpars.right\n","    t = ax.figure.subplotpars.top\n","    b = ax.figure.subplotpars.bottom\n","    figw = float(w)/(r-l)\n","    figh = float(h)/(t-b)\n","    ax.figure.set_size_inches(figw, figh)\n","\n","x_shift = stride_size//2\n","x = np.linspace(x_shift, clip_length - stride_size//2, num=n_segments)\n","y = np.ones(n_segments)\n","colors = predictions\n","area = 100 + is_marvins * 500\n","\n","fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(24,3))\n","\n","ax1.plot(tensor.numpy(), color='white')\n","ax1.axis('off')\n","\n","ax2.scatter(x, y, s=area, c=colors, alpha=0.9, cmap='RdYlGn')\n","ax2.axis('off')\n","set_size(24, 1, ax=ax2)\n","\n","fig.tight_layout(rect=[0, 0, 1, 1])\n","plt.show()\n","plt.ioff()\n","\n","# Visualize outputs\n","for i, item in enumerate(zip(audio_dataset, predictions)):\n","    audio, prediction = item\n","    is_marvin = prediction > 0.5\n","    audio_data = audio.numpy().squeeze()\n","\n","    displays = []\n","    #displays.append(f\"{str(is_marvin).capitalize()}\")\n","    displays.append(display.Audio(audio_data, rate=16_000))\n","\n","    buf = io.BytesIO()\n","    fig = plt.figure(figsize=(8,1.2))\n","    plt.plot(audio_data, color='green' if is_marvin else 'grey')\n","    plt.axis('off')\n","    fig.tight_layout(rect=[0, 0, 1, 1])\n","    plt.savefig(buf, format='png', transparent=True)\n","    plt.close(fig)\n","    buf.seek(0)\n","\n","    displays.append(display.Image(buf.read()))\n","    display.display(*displays)\n","    print('\\n')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E1-hVE75P-Xn"},"source":["##### TensorBoard"]},{"cell_type":"code","metadata":{"id":"UHwu1cpXLsM7"},"source":["#https://76bdzjdczr36-496ff2e9c6d22116-6006-colab.googleusercontent.com/#scalars\n","import tensorboard as tb\n","%reload_ext tensorboard\n","%tensorboard --logdir logs/rnn --port 6006\n","display.clear_output(wait=False)\n","tb.notebook.display(height=1400)"],"execution_count":null,"outputs":[]}]}