{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2IeYCIBkvX6"
   },
   "outputs": [],
   "source": [
    "# Project info\n",
    "PROJECT_ID = 'marvin-voice'\n",
    "GIT_OWNER, GIT_REPO = 'patrikkj', 'marvin-models'\n",
    "DATASET = 'dataset'\n",
    "\n",
    "# Set current working directory to project root\n",
    "import os\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    %cd -q ..\n",
    "    \n",
    "# Identify environment\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2IeYCIBkvX6"
   },
   "outputs": [],
   "source": [
    "# Run this cell only if we're running from Google Colab\n",
    "if IN_COLAB:\n",
    "    !git clone -q https://github.com/{GIT_OWNER}/{GIT_REPO}.git\n",
    "    !gsutil -q cp gs://{PROJECT_ID}/data/raw/{DATASET}.tar.gz /tmp\n",
    "    !tar -xf /tmp/{DATASET}.tar.gz -C /content/{GIT_REPO}/data\n",
    "    import sys\n",
    "    sys.path.append(f\"/content/{GIT_REPO}\")\n",
    "else:\n",
    "    !gsutil -q cp gs://{PROJECT_ID}/data/raw/{DATASET}.tar.gz data\n",
    "    !tar -xf data/{DATASET}.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal modules\n",
    "import os, sys, glob\n",
    "from importlib import reload\n",
    "\n",
    "# External modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow_io import experimental as tfex\n",
    "\n",
    "# Colab modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import auth\n",
    "    from IPython import display\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    \n",
    "# Scripts\n",
    "from scripts import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = reload(preprocessing)\n",
    "\n",
    "paths = glob.glob(f\"data/dataset/*/*.wav\")\n",
    "paths = paths[:500] + paths[-500:]\n",
    "\n",
    "tensors = [preprocessing.to_tensor(path) for path in paths]\n",
    "specs = [preprocessing.tensor_to_log_mel_spec(tensor) for tensor in tensors]\n",
    "mfccs = [preprocessing.batch_log_mel_spec_to_mfccs(spec) for spec in specs]\n",
    "\n",
    "labels = [preprocessing.to_binary_label(path) for path in paths]\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((specs, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = reload(preprocessing)\n",
    "\n",
    "paths = glob.glob(f\"data/dataset/*/*.wav\")\n",
    "\n",
    "tensors_arr = np.array([preprocessing.to_tensor(path) for path in paths])\n",
    "labels_arr = np.array([preprocessing.to_binary_label(path) for path in paths])\n",
    "\n",
    "print(tensors_arr.shape)\n",
    "print(labels_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.array(tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines ratios, w.r.t. whole dataset.\n",
    "ratio_train = 0.8\n",
    "ratio_val = 0.1\n",
    "ratio_test = 0.1\n",
    "\n",
    "# Produces test split.\n",
    "x_remaining, x_test, y_remaining, y_test = train_test_split(\n",
    "    x, y, test_size=test_ratio)\n",
    "\n",
    "# Adjusts val ratio, w.r.t. remaining dataset.\n",
    "ratio_remaining = 1 - ratio_test\n",
    "ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "\n",
    "# Produces train and val splits.\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_remaining, y_remaining, test_size=ratio_val_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((mfccs, labels))\n",
    "\"\"\"\n",
    "for tensor, label in dataset.take(5):\n",
    "    print(tensor.shape)\n",
    "    print(label.shape)\n",
    "    print()\n",
    "\"\"\"\n",
    "dataset = dataset.shuffle(10000).batch(512)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import record_audio\n",
    "audio, sr = record_audio.get_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
